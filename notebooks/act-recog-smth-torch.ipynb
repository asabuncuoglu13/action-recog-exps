{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.data.data import SomethingSomethingV2\n",
    "from torch.multiprocessing import cpu_count\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/datasets/20bn_something_something/v2/\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SomethingSomethingV2(root=data_root, mode='train')\n",
    "valid_dataset = SomethingSomethingV2(root=data_root, mode='validation')\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers= min(cpu_count(), 2))\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers= min(cpu_count(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, groups=1, bias=False):\n",
    "        super(AttentionConv3d, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.groups = groups\n",
    "\n",
    "        assert self.out_channels % self.groups == 0, \"out_channels should be divided by groups. (example: out_channels: 40, groups: 4)\"\n",
    "\n",
    "        self.rel_h = nn.Parameter(torch.randn(out_channels // 2, 1, 1, kernel_size, 1), requires_grad=True)\n",
    "        self.rel_w = nn.Parameter(torch.randn(out_channels // 2, 1, 1, 1, kernel_size), requires_grad=True)\n",
    "\n",
    "        self.key_conv = nn.Conv3d(in_channels, out_channels, kernel_size=3, bias=bias)\n",
    "        self.query_conv = nn.Conv3d(in_channels, out_channels, kernel_size=3, bias=bias)\n",
    "        self.value_conv = nn.Conv3d(in_channels, out_channels, kernel_size=3, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, height, width, d = x.size()\n",
    "        #print(\"x size:\", x.size())\n",
    "\n",
    "        pad = nn.ReplicationPad3d(self.padding)\n",
    "        padded_x = pad(x)\n",
    "        #print(\"padded x size:\", padded_x.size())\n",
    "        \n",
    "        q_out = self.query_conv(x)\n",
    "        #print(\"q_out:\", q_out.shape)\n",
    "        \n",
    "        k_out = self.key_conv(x)\n",
    "        #print(\"k_out:\", k_out.shape)\n",
    "        \n",
    "        v_out = self.value_conv(x)\n",
    "        #print(\"v_out:\", v_out.shape)\n",
    "        \n",
    "        k_out = k_out.contiguous().view(batch, self.groups, self.out_channels // self.groups, height - self.padding, width - self.padding, d - self.padding, -1)\n",
    "        v_out = v_out.contiguous().view(batch, self.groups, self.out_channels // self.groups, height - self.padding, width - self.padding, d - self.padding, -1)\n",
    "\n",
    "        q_out = q_out.view(batch, self.groups, self.out_channels // self.groups, height - self.padding, width - self.padding, d - self.padding, 1)\n",
    "        \n",
    "        out = torch.matmul(q_out, (k_out).transpose(-1, -2))\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        out = torch.matmul(out, v_out).view(batch, -1, height- self.padding, width - self.padding, d - self.padding)\n",
    "        return out\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_normal_(self.key_conv.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.value_conv.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.query_conv.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        init.normal_(self.rel_h, 0, 1)\n",
    "        init.normal_(self.rel_w, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNNModel,self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv3d(3, 3, 3)\n",
    "        self.pool0 = nn.MaxPool3d(4)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            AttentionConv3d(3, 8, kernel_size=5, padding=2, groups=2),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU(),\n",
    "        )        \n",
    "        #self.conv1 = nn.Conv3d(3,8,3)\n",
    "        self.conv2 = nn.Conv3d(8,32,3)\n",
    "        self.conv3 = nn.Conv3d(32,32,3)\n",
    "        # self.conv4 = nn.Conv3d(64,128,3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool3d(4)\n",
    "        self.linear1 = nn.Linear(512,256)\n",
    "        self.linear2 = nn.Linear(256,174)\n",
    "        self.batchnorm = nn.BatchNorm3d(32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        if downsampling:\n",
    "            x = self.conv0(x)\n",
    "            x = self.pool0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        #x = self.conv3(x)\n",
    "        # x = self.conv4(x)\n",
    "        # x = self.pool1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "model = CNNModel()\n",
    "model = model.cuda()\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.00005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 578/5279 [1:11:18<8:43:28,  6.68s/it] "
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_acc = 0\n",
    "    train_loss = 0\n",
    "    for x, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda())\n",
    "        #logits = model(x)\n",
    "        loss = error(logits, labels.cuda())\n",
    "        #loss = error(logits, labels)\n",
    "        train_loss+=loss.data\n",
    "        train_accuracy = accuracy_score(torch.argmax(logits,axis = 1).cpu().numpy(),labels.cpu().numpy())\n",
    "        running_acc+=train_accuracy*len(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    running_acc/=len(train_ds)\n",
    "    train_loss/=5\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            test = x.cuda()\n",
    "            outputs = model(test).detach()\n",
    "            test_loss = error(outputs,labels.cuda())\n",
    "            test_accuracy = accuracy_score(torch.argmax(outputs,axis = 1).cpu().numpy(),labels.cpu().numpy())\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss.data)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, \"model.pt\")\n",
    "    print('Epoch: {}  Train Loss:{:.2f}, Test Loss:{:.2f}, Train Accuracy:{:.2f}, Test Accuracy:{:.2f}'.format(epoch, train_loss,test_loss,train_accuracy,test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
